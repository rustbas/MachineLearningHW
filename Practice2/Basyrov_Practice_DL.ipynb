{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basyrov_Practice_DL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70bd7cb315f2455f8de25188337d5a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f830c7700fc54af68842edee2448ec65",
              "IPY_MODEL_378f7e22d9b24b7aa2c7912d510f8bbc",
              "IPY_MODEL_d734c67a0a6f42fd898052c3298e5dfa"
            ],
            "layout": "IPY_MODEL_6f33fec804084b42a77980449d33993c"
          }
        },
        "f830c7700fc54af68842edee2448ec65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0c960a3c73e4699a7173602e2a61f5f",
            "placeholder": "​",
            "style": "IPY_MODEL_a8b05cd96b0c498593c04e2f22825859",
            "value": ""
          }
        },
        "378f7e22d9b24b7aa2c7912d510f8bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2405aea814624cb99823d7ad2f28cde7",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65d1b4a6d98143ae8a936992616f74f4",
            "value": 170498071
          }
        },
        "d734c67a0a6f42fd898052c3298e5dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3e5032574ce4b398bebdff469a75928",
            "placeholder": "​",
            "style": "IPY_MODEL_1ffe322af10e4da8bbd9942d606d530e",
            "value": " 170499072/? [00:03&lt;00:00, 34692124.77it/s]"
          }
        },
        "6f33fec804084b42a77980449d33993c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0c960a3c73e4699a7173602e2a61f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8b05cd96b0c498593c04e2f22825859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2405aea814624cb99823d7ad2f28cde7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65d1b4a6d98143ae8a936992616f74f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3e5032574ce4b398bebdff469a75928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ffe322af10e4da8bbd9942d606d530e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rustbas/MachineLearningHW/blob/main/Practice2/Basyrov_Practice_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At-vE2wZwGq7"
      },
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0YzElsbwY-Z"
      },
      "source": [
        "# Практикум 3, DL for images\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CkwvRXh2h-G"
      },
      "source": [
        "## 1. Пример работы со свертками \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "70bd7cb315f2455f8de25188337d5a2a",
            "f830c7700fc54af68842edee2448ec65",
            "378f7e22d9b24b7aa2c7912d510f8bbc",
            "d734c67a0a6f42fd898052c3298e5dfa",
            "6f33fec804084b42a77980449d33993c",
            "c0c960a3c73e4699a7173602e2a61f5f",
            "a8b05cd96b0c498593c04e2f22825859",
            "2405aea814624cb99823d7ad2f28cde7",
            "65d1b4a6d98143ae8a936992616f74f4",
            "e3e5032574ce4b398bebdff469a75928",
            "1ffe322af10e4da8bbd9942d606d530e"
          ]
        },
        "id": "6ylVOrzTEDGG",
        "outputId": "7873eb31-808b-41ed-9b94-7540bfb410df"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "training_data = datasets.CIFAR10(\n",
        "    root='data',\n",
        "    train=True, \n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root='data',\n",
        "    train=False, \n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_data, batch_size=128, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70bd7cb315f2455f8de25188337d5a2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abwVD97jEGn-"
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxaOnGpvEGqW"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-fKF4HP3x8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca19e199-a626-440e-a40f-8ff34ce098af"
      },
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 0:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.001\n",
            "[1,   101] loss: 0.115\n",
            "[1,   201] loss: 0.115\n",
            "[1,   301] loss: 0.115\n",
            "[2,     1] loss: 0.001\n",
            "[2,   101] loss: 0.115\n",
            "[2,   201] loss: 0.115\n",
            "[2,   301] loss: 0.115\n",
            "[3,     1] loss: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar6MX5lM3Ppa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7228eb29-d9cc-4886-90aa-e3a8aa230031"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 44 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0prEH1Q1IAFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d5a9d6-feda-45cc-a685-e530cb65d6dd"
      },
      "source": [
        "# prepare to count predictions for each class\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                   accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class plane is: 42.3 %\n",
            "Accuracy for class car   is: 63.9 %\n",
            "Accuracy for class bird  is: 29.6 %\n",
            "Accuracy for class cat   is: 26.4 %\n",
            "Accuracy for class deer  is: 19.4 %\n",
            "Accuracy for class dog   is: 46.2 %\n",
            "Accuracy for class frog  is: 56.6 %\n",
            "Accuracy for class horse is: 56.6 %\n",
            "Accuracy for class ship  is: 55.9 %\n",
            "Accuracy for class truck is: 49.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUk__4JR-7sE"
      },
      "source": [
        "# Задание 1\n",
        "\n",
        "Написать и обучить нейронную сеть на датасете CIFAR (5 баллов)\n",
        "1. Замените сверточные слои размера 5х5 на два идущих подряд слоя размером 3х3\n",
        "2. Обучите модель на GPU, 20 эпох\n",
        "\n",
        "\n",
        "Дополнительно:\n",
        "1. (5 баллов) Переписать код с использованием pytorch lightning (см. документацию фреймворка https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Два слоя 3х3"
      ],
      "metadata": {
        "id": "FlO0v0IyeNnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "    self.conv2 = nn.Conv2d(6, 6, 3)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv3 = nn.Conv2d(6, 6, 3)\n",
        "    self.conv4 = nn.Conv2d(6, 16, 3)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv2(self.conv1(x))\n",
        "    # print('1 passed', x.shape)\n",
        "    x = self.pool(F.relu(x))\n",
        "    # print('2 passed', x.shape)\n",
        "    x = self.conv4(self.conv3(x))\n",
        "    # print('3 passed', x.shape)\n",
        "    x = self.pool(F.relu(x))\n",
        "    # print('4 passed', x.shape)\n",
        "    x = torch.flatten(x, 1)\n",
        "    # print('5 passed', x.shape)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    # print('6 passed', x.shape)\n",
        "    x = F.relu(self.fc2(x))\n",
        "    # print('7 passed', x.shape)\n",
        "    x = self.fc3(x)\n",
        "    # print('8 passed', x.shape)\n",
        " \n",
        "    # x = self.pool(F.relu(self.conv1(x)))\n",
        "    # x = self.pool(F.relu(self.conv2(x)))\n",
        "    # x = torch.flatten(x, 1)\n",
        "    # x = F.relu(self.fc1(x))\n",
        "    # x = F.relu(self.fc2(x))\n",
        "    # x = self.fc3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "6-cGanO_e_Hy"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = CNN()\n",
        "cuda0 = torch.device('cuda')\n",
        "model.to(cuda0)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)"
      ],
      "metadata": {
        "id": "DX08DI0LhHXW"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Обучение на 20 эпохах"
      ],
      "metadata": {
        "id": "vCCV8Mx1ty_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 20\n",
        "\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(cuda0), data[1].to(cuda0)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        # print(outputs.device, inputs.device)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        # if i % 100 == 0:    # print every 2000 mini-batches\n",
        "        #     print(f'[{epoch+1:3d}, {i+1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "        #           # (epoch + 1, i + 1, running_loss / 2000))\n",
        "        #     running_loss = 0.0\n",
        "    print(f'Epoch:{epoch+1:3d}, Running Loss:{running_loss:.3f}')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRfSs9tkhveJ",
        "outputId": "fc5f6de3-a96c-446f-8734-9233b276cb7f"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1, Running Loss:481.190\n",
            "Epoch:  2, Running Loss:473.614\n",
            "Epoch:  3, Running Loss:464.994\n",
            "Epoch:  4, Running Loss:457.919\n",
            "Epoch:  5, Running Loss:450.200\n",
            "Epoch:  6, Running Loss:443.650\n",
            "Epoch:  7, Running Loss:435.540\n",
            "Epoch:  8, Running Loss:429.851\n",
            "Epoch:  9, Running Loss:422.252\n",
            "Epoch: 10, Running Loss:419.163\n",
            "Epoch: 11, Running Loss:412.038\n",
            "Epoch: 12, Running Loss:406.141\n",
            "Epoch: 13, Running Loss:401.435\n",
            "Epoch: 14, Running Loss:394.654\n",
            "Epoch: 15, Running Loss:389.568\n",
            "Epoch: 16, Running Loss:384.526\n",
            "Epoch: 17, Running Loss:378.779\n",
            "Epoch: 18, Running Loss:374.023\n",
            "Epoch: 19, Running Loss:371.148\n",
            "Epoch: 20, Running Loss:363.904\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Проверка"
      ],
      "metadata": {
        "id": "qaaO5q0Y2vEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(cuda0), data[1].to(cuda0)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Точность нейросети для {total} изображений: {100*correct/total:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA-XpQmLuuIW",
        "outputId": "0a81ae39-df16-4aef-ee95-6597cf69ecf4"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность нейросети для 10000 изображений: 80.550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(cuda0), data[1].to(cuda0)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Точность нейросети для класса \\'{classname:7s}\\': {accuracy:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqwe5tBTvNzT",
        "outputId": "6aa9c254-8bbb-4d37-830e-0654846bdb46"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность нейросети для класса 'plane  ': 86.100\n",
            "Точность нейросети для класса 'car    ': 92.200\n",
            "Точность нейросети для класса 'bird   ': 71.100\n",
            "Точность нейросети для класса 'cat    ': 69.900\n",
            "Точность нейросети для класса 'deer   ': 74.100\n",
            "Точность нейросети для класса 'dog    ': 67.700\n",
            "Точность нейросети для класса 'frog   ': 90.000\n",
            "Точность нейросети для класса 'horse  ': 79.000\n",
            "Точность нейросети для класса 'ship   ': 85.400\n",
            "Точность нейросети для класса 'truck  ': 90.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUnx7Kq8L5ly"
      },
      "source": [
        "# Задание 2 (5 баллов)\n",
        "1. Обучитите на GPU претренированную модель VGG (минимум 5 эпох)\n",
        "2. Протестируйте ее на всех данных и на каждом классе отдельно\n",
        "\n",
        "Дополнительное задание (5 баллов):     \n",
        "\n",
        "* Взять какой-нибудь специфичный датасет с картинками\n",
        "* Взять претренированную VGG (или другу модель) и сделать transfer learning на выбранный датасет"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Обучение VGG на GPU"
      ],
      "metadata": {
        "id": "AVIPQyLGvo1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "vgg11 = models.vgg11(pretrained=True).to(cuda0)"
      ],
      "metadata": {
        "id": "co_UsWUBw-iY"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vgg11.parameters(), lr = 0.001, momentum = 0.9)"
      ],
      "metadata": {
        "id": "n3I-7V1XxC7P"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(cuda0), data[1].to(cuda0)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = vgg11(inputs)\n",
        "        # print(outputs.device, inputs.device)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        # if i % 100 == 0:    # print every 2000 mini-batches\n",
        "        #     print(f'[{epoch+1:3d}, {i+1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "        #           # (epoch + 1, i + 1, running_loss / 2000))\n",
        "        #     running_loss = 0.0\n",
        "    print(f'Epoch:{epoch+1:3d}, Running Loss:{running_loss:.3f}')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m6gh31FysgA",
        "outputId": "d255afa8-d8c7-462e-9bb7-7c3b2416dc39"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1, Running Loss:608.136\n",
            "Epoch:  2, Running Loss:297.171\n",
            "Epoch:  3, Running Loss:233.240\n",
            "Epoch:  4, Running Loss:195.237\n",
            "Epoch:  5, Running Loss:161.304\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Проверка"
      ],
      "metadata": {
        "id": "e4WoGDOQ1Kyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Проверка на всех классах"
      ],
      "metadata": {
        "id": "x0aiOyCH2bun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "vgg11.eval()\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(cuda0), data[1].to(cuda0)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = vgg11(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Точность VGG11 для {total} изображений: {100*correct/total:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNB9zbSW2glC",
        "outputId": "3ac49509-1470-41c0-9035-9fc686deab87"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность VGG11 для 10000 изображений: 82.140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 Проверка на каждом классе отдельно"
      ],
      "metadata": {
        "id": "SHNTDHziGNDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(cuda0), data[1].to(cuda0)\n",
        "        outputs = vgg11(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Точность VGG11 для класса \\'{classname:7s}\\': {accuracy:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKJDl-5AIuWw",
        "outputId": "59ed91ed-6117-4ebb-9ea1-23b70747adc2"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность VGG11 для класса 'plane  ': 82.200\n",
            "Точность VGG11 для класса 'car    ': 91.800\n",
            "Точность VGG11 для класса 'bird   ': 73.100\n",
            "Точность VGG11 для класса 'cat    ': 69.700\n",
            "Точность VGG11 для класса 'deer   ': 77.700\n",
            "Точность VGG11 для класса 'dog    ': 76.200\n",
            "Точность VGG11 для класса 'frog   ': 83.700\n",
            "Точность VGG11 для класса 'horse  ': 86.600\n",
            "Точность VGG11 для класса 'ship   ': 90.000\n",
            "Точность VGG11 для класса 'truck  ': 90.400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.3 Датасет - CIFAR100, модель - ResNet18"
      ],
      "metadata": {
        "id": "eF0ZiOsZLHJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Данные"
      ],
      "metadata": {
        "id": "eVrvrDFVLKyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "training_data = datasets.CIFAR100(\n",
        "    root='data',\n",
        "    train=True, \n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = datasets.CIFAR100(\n",
        "    root='data',\n",
        "    train=False, \n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_data, batch_size=128, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_KddPrHLeuY",
        "outputId": "b1d61ca8-0fa3-4358-c6a1-36856eb9473a"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes2 = [\n",
        "'beaver', 'dolphin', 'otter', 'seal', 'whale',\n",
        "'aquarium fish', 'flatfish', 'ray', 'shark', 'trout',\n",
        "'orchids', 'poppies', 'roses', 'sunflowers', 'tulips',\n",
        "'bottles', 'bowls', 'cans', 'cups', 'plates',\n",
        "'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers',\n",
        "'clock', 'computer keyboard', 'lamp', 'telephone', 'television',\n",
        "'bed', 'chair', 'couch', 'table', 'wardrobe',\n",
        "'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach',\n",
        "'bear', 'leopard', 'lion', 'tiger', 'wolf',\n",
        "'bridge', 'castle', 'house', 'road', 'skyscraper',\n",
        "'cloud', 'forest', 'mountain', 'plain', 'sea',\n",
        "'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo',\n",
        "'fox', 'porcupine', 'possum', 'raccoon', 'skunk',\n",
        "'crab', 'lobster', 'snail', 'spider', 'worm',\n",
        "'baby', 'boy', 'girl', 'man', 'woman',\n",
        "'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle',\n",
        "'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel',\n",
        "'maple', 'oak', 'palm', 'pine', 'willow',\n",
        "'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train',\n",
        "'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor',\n",
        "]"
      ],
      "metadata": {
        "id": "BSnqnYWdPTlS"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Модель"
      ],
      "metadata": {
        "id": "EDNzk6r-Lkih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NN = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True).to(cuda0).train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE-3A3iCMXJe",
        "outputId": "dc31339c-2e23-4270-b60b-cec5ba068a05"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Обучение"
      ],
      "metadata": {
        "id": "UqaX3BD2NNgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(NN.parameters(), lr = 0.001, momentum = 0.9)"
      ],
      "metadata": {
        "id": "92k756MwNmiC"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 7\n",
        "\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(cuda0), data[1].to(cuda0)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = NN(inputs)\n",
        "        # print(outputs.device, inputs.device)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        # if i % 100 == 0:    # print every 2000 mini-batches\n",
        "        #     print(f'[{epoch+1:3d}, {i+1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "        #           # (epoch + 1, i + 1, running_loss / 2000))\n",
        "        #     running_loss = 0.0\n",
        "    print(f'Epoch:{epoch+1:3d}, Running Loss:{running_loss:.3f}')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obLSt88zNWOV",
        "outputId": "4e0fb06f-e9d1-4f82-ea73-2c65030308d2"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1, Running Loss:1715.780\n",
            "Epoch:  2, Running Loss:977.478\n",
            "Epoch:  3, Running Loss:777.379\n",
            "Epoch:  4, Running Loss:657.721\n",
            "Epoch:  5, Running Loss:561.500\n",
            "Epoch:  6, Running Loss:475.513\n",
            "Epoch:  7, Running Loss:402.140\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Проверка на всех классах"
      ],
      "metadata": {
        "id": "KhznoYE_N5m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "NN.eval()\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(cuda0), data[1].to(cuda0)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = NN(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Точность ResNet18 для {total} изображений: {100*correct/total:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ0YyI1gOp37",
        "outputId": "1244a2cb-c80d-445a-fcbf-6614c8ccf0f7"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность нейросети для 10000 изображений: 50.170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Проверка на каждом классе"
      ],
      "metadata": {
        "id": "Q_v178KhQ9c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pred = {classname: 0 for classname in classes2}\n",
        "total_pred = {classname: 0 for classname in classes2}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(cuda0), data[1].to(cuda0)\n",
        "        outputs = NN(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes2[label]] += 1\n",
        "            total_pred[classes2[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Точность ResNet18 для класса \\'{classname:7s}\\': {accuracy:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJN3JG9PQ_d9",
        "outputId": "a9c3dbf7-0f80-4f13-e7ad-64cc1ebf6bcf"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность ResNet18 для класса 'beaver ': 79.000\n",
            "Точность ResNet18 для класса 'dolphin': 63.000\n",
            "Точность ResNet18 для класса 'otter  ': 40.000\n",
            "Точность ResNet18 для класса 'seal   ': 19.000\n",
            "Точность ResNet18 для класса 'whale  ': 34.000\n",
            "Точность ResNet18 для класса 'aquarium fish': 58.000\n",
            "Точность ResNet18 для класса 'flatfish': 53.000\n",
            "Точность ResNet18 для класса 'ray    ': 55.000\n",
            "Точность ResNet18 для класса 'shark  ': 58.000\n",
            "Точность ResNet18 для класса 'trout  ': 60.000\n",
            "Точность ResNet18 для класса 'orchids': 44.000\n",
            "Точность ResNet18 для класса 'poppies': 31.000\n",
            "Точность ResNet18 для класса 'roses  ': 55.000\n",
            "Точность ResNet18 для класса 'sunflowers': 29.000\n",
            "Точность ResNet18 для класса 'tulips ': 43.000\n",
            "Точность ResNet18 для класса 'bottles': 45.000\n",
            "Точность ResNet18 для класса 'bowls  ': 57.000\n",
            "Точность ResNet18 для класса 'cans   ': 55.000\n",
            "Точность ResNet18 для класса 'cups   ': 49.000\n",
            "Точность ResNet18 для класса 'plates ': 36.000\n",
            "Точность ResNet18 для класса 'apples ': 70.000\n",
            "Точность ResNet18 для класса 'mushrooms': 77.000\n",
            "Точность ResNet18 для класса 'oranges': 49.000\n",
            "Точность ResNet18 для класса 'pears  ': 82.000\n",
            "Точность ResNet18 для класса 'sweet peppers': 55.000\n",
            "Точность ResNet18 для класса 'clock  ': 28.000\n",
            "Точность ResNet18 для класса 'computer keyboard': 43.000\n",
            "Точность ResNet18 для класса 'lamp   ': 37.000\n",
            "Точность ResNet18 для класса 'telephone': 66.000\n",
            "Точность ResNet18 для класса 'television': 49.000\n",
            "Точность ResNet18 для класса 'bed    ': 49.000\n",
            "Точность ResNet18 для класса 'chair  ': 47.000\n",
            "Точность ResNet18 для класса 'couch  ': 41.000\n",
            "Точность ResNet18 для класса 'table  ': 44.000\n",
            "Точность ResNet18 для класса 'wardrobe': 46.000\n",
            "Точность ResNet18 для класса 'bee    ': 29.000\n",
            "Точность ResNet18 для класса 'beetle ': 43.000\n",
            "Точность ResNet18 для класса 'butterfly': 43.000\n",
            "Точность ResNet18 для класса 'caterpillar': 34.000\n",
            "Точность ResNet18 для класса 'cockroach': 81.000\n",
            "Точность ResNet18 для класса 'bear   ': 43.000\n",
            "Точность ResNet18 для класса 'leopard': 68.000\n",
            "Точность ResNet18 для класса 'lion   ': 55.000\n",
            "Точность ResNet18 для класса 'tiger  ': 48.000\n",
            "Точность ResNet18 для класса 'wolf   ': 25.000\n",
            "Точность ResNet18 для класса 'bridge ': 32.000\n",
            "Точность ResNet18 для класса 'castle ': 25.000\n",
            "Точность ResNet18 для класса 'house  ': 52.000\n",
            "Точность ResNet18 для класса 'road   ': 84.000\n",
            "Точность ResNet18 для класса 'skyscraper': 71.000\n",
            "Точность ResNet18 для класса 'cloud  ': 20.000\n",
            "Точность ResNet18 для класса 'forest ': 47.000\n",
            "Точность ResNet18 для класса 'mountain': 53.000\n",
            "Точность ResNet18 для класса 'plain  ': 85.000\n",
            "Точность ResNet18 для класса 'sea    ': 64.000\n",
            "Точность ResNet18 для класса 'camel  ': 15.000\n",
            "Точность ResNet18 для класса 'cattle ': 79.000\n",
            "Точность ResNet18 для класса 'chimpanzee': 60.000\n",
            "Точность ResNet18 для класса 'elephant': 52.000\n",
            "Точность ResNet18 для класса 'kangaroo': 61.000\n",
            "Точность ResNet18 для класса 'fox    ': 65.000\n",
            "Точность ResNet18 для класса 'porcupine': 61.000\n",
            "Точность ResNet18 для класса 'possum ': 57.000\n",
            "Точность ResNet18 для класса 'raccoon': 43.000\n",
            "Точность ResNet18 для класса 'skunk  ': 20.000\n",
            "Точность ResNet18 для класса 'crab   ': 31.000\n",
            "Точность ResNet18 для класса 'lobster': 41.000\n",
            "Точность ResNet18 для класса 'snail  ': 37.000\n",
            "Точность ResNet18 для класса 'spider ': 81.000\n",
            "Точность ResNet18 для класса 'worm   ': 76.000\n",
            "Точность ResNet18 для класса 'baby   ': 63.000\n",
            "Точность ResNet18 для класса 'boy    ': 50.000\n",
            "Точность ResNet18 для класса 'girl   ': 19.000\n",
            "Точность ResNet18 для класса 'man    ': 49.000\n",
            "Точность ResNet18 для класса 'woman  ': 35.000\n",
            "Точность ResNet18 для класса 'crocodile': 76.000\n",
            "Точность ResNet18 для класса 'dinosaur': 79.000\n",
            "Точность ResNet18 для класса 'lizard ': 38.000\n",
            "Точность ResNet18 для класса 'snake  ': 43.000\n",
            "Точность ResNet18 для класса 'turtle ': 49.000\n",
            "Точность ResNet18 для класса 'hamster': 23.000\n",
            "Точность ResNet18 для класса 'mouse  ': 50.000\n",
            "Точность ResNet18 для класса 'rabbit ': 72.000\n",
            "Точность ResNet18 для класса 'shrew  ': 47.000\n",
            "Точность ResNet18 для класса 'squirrel': 35.000\n",
            "Точность ResNet18 для класса 'maple  ': 57.000\n",
            "Точность ResNet18 для класса 'oak    ': 62.000\n",
            "Точность ResNet18 для класса 'palm   ': 63.000\n",
            "Точность ResNet18 для класса 'pine   ': 45.000\n",
            "Точность ResNet18 для класса 'willow ': 47.000\n",
            "Точность ResNet18 для класса 'bicycle': 50.000\n",
            "Точность ResNet18 для класса 'bus    ': 57.000\n",
            "Точность ResNet18 для класса 'motorcycle': 33.000\n",
            "Точность ResNet18 для класса 'pickup truck': 29.000\n",
            "Точность ResNet18 для класса 'train  ': 79.000\n",
            "Точность ResNet18 для класса 'lawn-mower': 62.000\n",
            "Точность ResNet18 для класса 'rocket ': 43.000\n",
            "Точность ResNet18 для класса 'streetcar': 51.000\n",
            "Точность ResNet18 для класса 'tank   ': 22.000\n",
            "Точность ResNet18 для класса 'tractor': 62.000\n"
          ]
        }
      ]
    }
  ]
}