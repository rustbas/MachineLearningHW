{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайные леса\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "В этом задании вам предстоит реализовать ансамбль деревьев решений, известный как случайный лес, применить его к публичным данным и сравнить его эффективность с ансамблями из самых популярных библиотек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:09.967800Z",
     "start_time": "2022-03-09T19:57:08.993100Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from scipy.stats import mode\n",
    "from inspect import stack\n",
    "from scipy.integrate import simps, trapz\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:10.113905Z",
     "start_time": "2022-03-09T19:57:10.110921Z"
    }
   },
   "outputs": [],
   "source": [
    "def subtotals(x):\n",
    "    X = sorted(list(set(x)))\n",
    "#     print(X)\n",
    "    res = np.zeros(len(X)-1)\n",
    "    for i in range(len(X) - 1):\n",
    "        res[i] = (X[i] + X[i+1])/2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:10.361748Z",
     "start_time": "2022-03-09T19:57:10.359687Z"
    }
   },
   "outputs": [],
   "source": [
    "def f():\n",
    "    return len(stack())-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:10.543343Z",
     "start_time": "2022-03-09T19:57:10.537394Z"
    }
   },
   "outputs": [],
   "source": [
    "def gini(x_in):\n",
    "    x = np.array(x_in)\n",
    "    labels = list(set(x_in))\n",
    "    m = len(labels)\n",
    "    n = len(x)\n",
    "    Y = dict()\n",
    "    for i in range(max(labels)+1):\n",
    "#         print(x.shape, type(x), x)\n",
    "        Y[i] = 0\n",
    "\n",
    "    for i in range(n):\n",
    "#         print(Y, type(x), x)\n",
    "        key = x[i]\n",
    "#         print(type(float(key)))\n",
    "        Y[x[i]] += 1/n\n",
    "    \n",
    "    S = 0\n",
    "    for key in Y.keys():\n",
    "        S += Y[key]*(1 - Y[key])\n",
    "        \n",
    "    \n",
    "    return S\n",
    "    \n",
    "def entropy(x_in):\n",
    "    x = np.array(x_in)\n",
    "    labels = list(set(x))\n",
    "    m = len(labels)\n",
    "    n = len(x)\n",
    "    Y = {label:0 for label in labels}\n",
    "    \n",
    "    for i in range(n):\n",
    "        Y[x[i]] += 1/n\n",
    "        \n",
    "    S = 0\n",
    "    \n",
    "    for key in Y.keys():\n",
    "        S -= Y[key]*np.log2(Y[key])\n",
    "    return S\n",
    "\n",
    "def gain(left_y, right_y, criterion):\n",
    "    y = list(left_y) + list(right_y)\n",
    "    n_left = len(left_y)\n",
    "    n_right = len(right_y)\n",
    "    n_all = n_left + n_right\n",
    "    return (n_all*criterion(y) - n_right*criterion(right_y) - n_left*criterion(left_y))/n_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:10.786441Z",
     "start_time": "2022-03-09T19:57:10.783331Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTreeLeaf:\n",
    "    def __init__(self, y):\n",
    "#         self.mode = mode(y)[0][0]\n",
    "        self.N = len(y)\n",
    "        self.set = list(set(y))\n",
    "        self.y = list(y)\n",
    "#         raise NotImplementedError()\n",
    "\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, split_dim, split_value, left, right):\n",
    "        self.split_dim = split_dim\n",
    "        self.split_value = split_value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "#         raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:11.243537Z",
     "start_time": "2022-03-09T19:57:11.232544Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "\n",
    "    def __init__(self, criterion=\"gini\", max_depth=None, min_samples_leaf=1):\n",
    "        self.root = None\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_depth = max_depth\n",
    "        if criterion == 'gini':\n",
    "            self.criterion = gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.criterion = entropy\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    def build(self, X, y):\n",
    "        cur_rec = f()\n",
    "        \n",
    "        min_IG = -np.inf\n",
    "        test = False\n",
    "#         print(X.columns)\n",
    "        res_column = None\n",
    "        res_threshold = np.inf\n",
    "        for column in X.columns:\n",
    "            X_temp = X[column]\n",
    "            if len(set(X_temp)) > 300:\n",
    "                thresholds = subtotals(np.array(X_temp))[::len(X_temp)//10]\n",
    "            else:\n",
    "                thresholds = sorted(list(set(X_temp)))\n",
    "            for threshold in thresholds:\n",
    "                left = y[X_temp < threshold]\n",
    "                right = y[X_temp >= threshold]\n",
    "                if len(left) <= self.min_samples_leaf or len(right) <= self.min_samples_leaf:\n",
    "                    continue\n",
    "                IG = gain(left, right, self.criterion)\n",
    "                if IG > min_IG: \n",
    "                    test = True\n",
    "                    res_column = column\n",
    "                    min_IG = IG\n",
    "                    res_threshold = threshold\n",
    "        \n",
    "        if res_column is not None:\n",
    "            yl = y[X[res_column] < res_threshold]\n",
    "            yr = y[X[res_column] >= res_threshold]\n",
    "            Xl = X[X[res_column] < res_threshold].drop(res_column, axis=1)\n",
    "            Xr = X[X[res_column] >= res_threshold].drop(res_column, axis=1)\n",
    "            if self.max_depth is None:\n",
    "                key = False\n",
    "            elif cur_rec < self.max_depth:\n",
    "                key = False\n",
    "            else:\n",
    "                key = True\n",
    "        else:\n",
    "            key = True\n",
    "            \n",
    "\n",
    "        if (key) or len(list(X.columns))<=1 or X.empty or res_threshold == np.inf:\n",
    "            return DecisionTreeLeaf(y)\n",
    "        else:\n",
    "            return DecisionTreeNode(res_column, res_threshold,\n",
    "                                    self.build(Xl, yl),\n",
    "                                    self.build(Xr, yr))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build(X, y)\n",
    "\n",
    "    def search(self, x, Node):\n",
    "        if type(Node) is DecisionTreeLeaf:\n",
    "            res = dict()\n",
    "            for key in Node.set:\n",
    "                res[key] = Node.y.count(key)/Node.N\n",
    "            return res\n",
    "        elif type(Node) is DecisionTreeNode:\n",
    "            if x[Node.split_dim] < Node.split_value:\n",
    "                return self.search(x, Node.left)\n",
    "            elif x[Node.split_dim] >= Node.split_value:\n",
    "                return self.search(x, Node.right)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "    def predict_proba(self, X_in):\n",
    "        X = X_in#.drop('Id', axis=1)\n",
    "#         IDs = X_in.Id\n",
    "        pred = []\n",
    "        N = len(X)\n",
    "        for i in range(N):\n",
    "            x = X.iloc[i]\n",
    "            pred += [self.search(x, self.root)]\n",
    "        \n",
    "        return pred\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.array([max(p.keys(), key=lambda k: p[k]) for p in proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:11.497692Z",
     "start_time": "2022-03-09T19:57:11.491264Z"
    }
   },
   "outputs": [],
   "source": [
    "def tree_depth(tree_root):\n",
    "    if isinstance(tree_root, DecisionTreeNode):\n",
    "        return max(tree_depth(tree_root.left), tree_depth(tree_root.right)) + 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def draw_tree_rec(tree_root, x_left, x_right, y):\n",
    "    x_center = (x_right - x_left) / 2 + x_left\n",
    "    if isinstance(tree_root, DecisionTreeNode):\n",
    "        x_center = (x_right - x_left) / 2 + x_left\n",
    "        x = draw_tree_rec(tree_root.left, x_left, x_center, y - 1)\n",
    "        plt.plot((x_center, x), (y - 0.1, y - 0.9), c=(0, 0, 0))\n",
    "        x = draw_tree_rec(tree_root.right, x_center, x_right, y - 1)\n",
    "        plt.plot((x_center, x), (y - 0.1, y - 0.9), c=(0, 0, 0))\n",
    "        plt.text(x_center, y, \"x[%i] < %f\" % (tree_root.split_dim, tree_root.split_value),\n",
    "                horizontalalignment='center')\n",
    "    else:\n",
    "        plt.text(x_center, y, str(tree_root.y),\n",
    "                horizontalalignment='center')\n",
    "    return x_center\n",
    "\n",
    "def draw_tree(tree, save_path=None):\n",
    "    td = tree_depth(tree.root)\n",
    "    plt.figure(figsize=(0.33 * 2 ** td, 2 * td))\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(0.95, td + 0.05)\n",
    "    plt.axis('off')\n",
    "    draw_tree_rec(tree.root, -1, 1, td)\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:12.432675Z",
     "start_time": "2022-03-09T19:57:12.408328Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, p_pred):\n",
    "    positive_samples = sum(1 for y in y_test if y == 0)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for w in np.arange(-0.01, 1.02, 0.01):\n",
    "        y_pred = [(0 if p.get(0, 0) > w else 1) for p in p_pred]\n",
    "        tpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt == 0) / positive_samples)\n",
    "        fpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt != 0) / (len(y_test) - positive_samples))\n",
    "    plt.figure(figsize = (7, 7))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.xlim(-0.01, 1.01)\n",
    "    plt.ylim(-0.01, 1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def rectangle_bounds(bounds):\n",
    "    return ((bounds[0][0], bounds[0][0], bounds[0][1], bounds[0][1]), \n",
    "            (bounds[1][0], bounds[1][1], bounds[1][1], bounds[1][0]))\n",
    "\n",
    "def plot_2d_tree(tree_root, bounds, colors):\n",
    "    if isinstance(tree_root, DecisionTreeNode):\n",
    "        if tree_root.split_dim:\n",
    "            plot_2d_tree(tree_root.left, [bounds[0], [bounds[1][0], tree_root.split_value]], colors)\n",
    "            plot_2d_tree(tree_root.right, [bounds[0], [tree_root.split_value, bounds[1][1]]], colors)\n",
    "            plt.plot(bounds[0], (tree_root.split_value, tree_root.split_value), c=(0, 0, 0))\n",
    "        else:\n",
    "            plot_2d_tree(tree_root.left, [[bounds[0][0], tree_root.split_value], bounds[1]], colors)\n",
    "            plot_2d_tree(tree_root.right, [[tree_root.split_value, bounds[0][1]], bounds[1]], colors)\n",
    "            plt.plot((tree_root.split_value, tree_root.split_value), bounds[1], c=(0, 0, 0))\n",
    "    else:\n",
    "        x, y = rectangle_bounds(bounds)\n",
    "        plt.fill(x, y, c=colors[tree_root.y] + [0.2])\n",
    "\n",
    "def plot_2d(tree, X, y):\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    colors = dict((c, list(np.random.random(3))) for c in np.unique(y))\n",
    "    bounds = list(zip(np.min(X, axis=0), np.max(X, axis=0)))\n",
    "    plt.xlim(*bounds[0])\n",
    "    plt.ylim(*bounds[1])\n",
    "    plot_2d_tree(tree.root, list(zip(np.min(X, axis=0), np.max(X, axis=0))), colors)\n",
    "    for c in np.unique(y):\n",
    "        plt.scatter(X[y==c, 0], X[y==c, 1], c=[colors[c]], label=c)\n",
    "    plt.legend()\n",
    "#     plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:14.770941Z",
     "start_time": "2022-03-09T19:57:14.760195Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def roc(proba):\n",
    "    res = []\n",
    "    for i in range(len(proba)):\n",
    "        try:\n",
    "            res += [proba[i][1]]\n",
    "        except KeyError:\n",
    "            res += [0]\n",
    "    return np.array(res)\n",
    "def AUC(y_test, proba):\n",
    "    y_pred = roc(proba)\n",
    "    tpr,fpr,_ = roc_curve(y_test, y_pred)\n",
    "    return auc(tpr, fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем сам Random Forest. Идея очень простая: строим `n` деревьев, а затем берем модальное предсказание. Используйте реализацию дерева из HW3.\n",
    "\n",
    "#### Параметры конструктора\n",
    "`n_estimators` - количество используемых для предсказания деревьев.\n",
    "\n",
    "Остальное - параметры деревьев.\n",
    "\n",
    "#### Методы\n",
    "`fit(X, y)` - строит `n_estimators` деревьев по выборке `X`.\n",
    "\n",
    "`predict(X)` - для каждого элемента выборки `X` возвращает самый частый класс, который предсказывают для него деревья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:20.051091Z",
     "start_time": "2022-03-09T19:57:20.026228Z"
    }
   },
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "\n",
    "    def __init__(self,\n",
    "                 criterion=\"gini\",\n",
    "                 max_depth=5,\n",
    "                 min_samples_leaf=30,\n",
    "                 max_features=\"auto\",\n",
    "                 n_estimators=10):\n",
    "\n",
    "        self.crit = criterion\n",
    "        self.max_d = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.forest = [\n",
    "            DecisionTreeClassifier(criterion=criterion,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_leaf=min_samples_leaf)\n",
    "            for _ in range(n_estimators)\n",
    "        ]\n",
    "        \n",
    "        self.cols = []\n",
    "\n",
    "        if max_features == 'auto' or max_features == 'sqrt':\n",
    "            self.max_features = 'sqrt'\n",
    "        elif max_features == 'log2':\n",
    "            self.max_features = 'log2'\n",
    "        elif type(max_features) is int:\n",
    "            self.max_features = max_features\n",
    "        else:\n",
    "            raise NotImplementedError('Неверное количество признаков')\n",
    "\n",
    "    def fit(self, X, y, n_sample = 300):\n",
    "        if self.max_features == 'sqrt':\n",
    "            self.sampling = round(np.sqrt(X.shape[1]))\n",
    "        elif self.max_features == 'log2':\n",
    "            self.sampling = round(np.log2(X.shape[1]))\n",
    "        elif type(self.max_features) is int:\n",
    "            self.sampling = self.max_features\n",
    "        else:\n",
    "            raise NotImplementedError('Неверное количество признаков')\n",
    "        \n",
    "        self.set = set()\n",
    "        for label in y:\n",
    "            self.set.add(label)\n",
    "        self.set = list(self.set)\n",
    "        \n",
    "        temp = pd.concat((X,y), axis = 1)\n",
    "        \n",
    "        sample = temp.sample(n_sample, replace=True)\n",
    "        \n",
    "        X_in = sample.drop(['Expected'], axis=1)\n",
    "        y_in = sample['Expected']\n",
    "        \n",
    "        for i in range(len(self.forest)):\n",
    "            X_temp = X_in.sample(self.sampling, axis=1)\n",
    "            self.cols += [X_in.columns]\n",
    "#             print(X_temp)\n",
    "            self.forest[i].fit(X_temp, y_in)\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = []\n",
    "        for i in range(len(self.forest)):\n",
    "#             print(self.cols[i])\n",
    "            X_temp = X[self.cols[i]]\n",
    "            proba += [self.forest[i].predict(X_temp)]\n",
    "            \n",
    "        return np.transpose(mode(np.array(proba))[0])\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        proba = []\n",
    "        for i in range(len(self.forest)):\n",
    "#             print(self.cols[i])\n",
    "            X_temp = X[self.cols[i]]\n",
    "            proba += [self.forest[i].predict(X_temp)]\n",
    "            \n",
    "        proba = np.array(proba).T\n",
    "        result = []\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            result += [dict()]\n",
    "            for label in range(max(self.set)+1):\n",
    "                result[i][label] = 0\n",
    "            \n",
    "        for i in range(len(X)):\n",
    "            temp = proba[i,:]\n",
    "            for key in result[i].keys():\n",
    "#                 print(key, np.sum(temp == key)/len(self.forest))\n",
    "                result[i][key] = np.sum(temp == key)/len(self.forest)\n",
    "#             print(result[i])\n",
    "#         print(result)    \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "Оптимизируйте по `AUC` на кроссвалидации (размер валидационной выборки - 20%) параметры своей реализации `Random Forest`: \n",
    "\n",
    "максимальную глубину деревьев из [2, 3, 5, 7, 10], количество деревьев из [5, 10, 20, 30, 50, 100]. \n",
    "\n",
    "Постройте `ROC` кривую (и выведите `AUC` и `accuracy`) для лучшего варианта.\n",
    "\n",
    "Подсказка: можно построить сразу 100 деревьев глубины 10, а потом убирать деревья и\n",
    "глубину."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:55.167544Z",
     "start_time": "2022-03-09T19:57:55.139667Z"
    }
   },
   "outputs": [],
   "source": [
    "all_X = pd.read_csv('x_spam_train.csv')\n",
    "all_y = pd.read_csv('y_spam_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:55.465560Z",
     "start_time": "2022-03-09T19:57:55.462630Z"
    }
   },
   "outputs": [],
   "source": [
    "depths = [2, 3, 5, 7, 10]\n",
    "n_trees = [5, 10, 20, 30, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:55.724634Z",
     "start_time": "2022-03-09T19:57:55.719247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 736), (736, 1472), (1472, 2208), (2208, 2944), (2944, 3680)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(all_X)\n",
    "n_splits = 5\n",
    "splits = [(i*N//n_splits, (i+1)*N//n_splits) for i in range(n_splits)] \n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:57:56.551970Z",
     "start_time": "2022-03-09T19:57:56.546555Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_AUC = -np.inf\n",
    "best_depth = 0\n",
    "best_n = 0\n",
    "best_proba = None\n",
    "best_y = None\n",
    "all_N = len(depths)*len(n_trees)*n_splits\n",
    "it = 0\n",
    "# for depth in depths:\n",
    "#     for n in n_trees:\n",
    "#         AUC_temp = 0\n",
    "#         for split in splits:\n",
    "#             print(f'{it+1}-ая итерация из {all_N}')\n",
    "#             it += 1\n",
    "#             X_test = all_X.iloc[split[0]:split[1]]\n",
    "#             X_train = pd.concat((all_X.iloc[split[1]:], all_X.iloc[:split[0]]))\n",
    "#             y_test = all_y['Expected'].iloc[split[0]:split[1]]\n",
    "#             y_train = pd.concat((all_y['Expected'].iloc[split[1]:],\n",
    "#                                  all_y['Expected'].iloc[:split[0]]))\n",
    "\n",
    "#             forest = RandomForestClassifier(criterion='gini',\n",
    "#                                             max_depth=depth,\n",
    "#                                             min_samples_leaf=30,\n",
    "#                                             n_estimators=n)\n",
    "            \n",
    "# #             print(X_train.columns)\n",
    "            \n",
    "#             forest.fit(X_train.drop('Id', axis=1), y_train, n_sample=150)\n",
    "#             proba = forest.predict_proba(X_test.drop('Id', axis=1))\n",
    "            \n",
    "#             AUC_temp += AUC(y_test, proba)/n_splits\n",
    "        \n",
    "#         if AUC_temp > max_AUC:\n",
    "# #             print(AUC_temp)\n",
    "#             max_AUC = AUC_temp\n",
    "#             best_depth = depth\n",
    "#             best_n = n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Обучите модель на всех данных из x_spam_train и y_spam_train.\n",
    "2. Сделайте submit своего решения и получите значение f1_score не менее 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:59:04.466785Z",
     "start_time": "2022-03-09T19:58:25.500882Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_leaf=30)\n",
    "all_X = pd.read_csv('x_spam_train.csv')\n",
    "all_y = pd.read_csv('y_spam_train.csv')['Expected']\n",
    "test_X = pd.read_csv('x_spam_test.csv')\n",
    "forest.fit(all_X.drop('Id', axis=1), all_y, n_sample=200)\n",
    "submission = pd.DataFrame(columns = [\"Id\", \"Expected\"])\n",
    "submission[\"Id\"] = test_X[\"Id\"]\n",
    "submission[\"Expected\"] = forest.predict(test_X)\n",
    "submission.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве альтернативы попробуем библиотечные реализации ансамблей моделей. \n",
    "\n",
    "1. [CatBoost](https://catboost.ai/docs/)\n",
    "2. [XGBoost](https://xgboost.readthedocs.io/en/latest/)\n",
    "3. [LightGBM](https://lightgbm.readthedocs.io/en/latest/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установите необходимые библиотеки. \n",
    "Возможно, потребуется установка дополнительных пакетов."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T11:09:41.554500Z",
     "start_time": "2022-03-09T11:08:22.824271Z"
    }
   },
   "source": [
    "!pip install lightgbm\n",
    "!pip install catboost\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Примените модели для нашего датасета.\n",
    "\n",
    "2. Для стандартного набора параметров у каждой модели нарисуйте `ROC` кривую и выведите `AUC` и `accuracy`.\n",
    "\n",
    "3. Посчитайте время обучения каждой модели (можно использовать [timeit magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit)).\n",
    "\n",
    "4. Сравните метрики качества и скорость обучения моделей. Какие выводы можно сделать?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:14:38.380688Z",
     "start_time": "2022-03-09T19:14:38.376022Z"
    }
   },
   "source": [
    "coef = 0.7\n",
    "X_train, y_train = all_X.iloc[:round(len(all_X)*coef)], all_y['Expected'].iloc[:round(len(all_X)*coef)]\n",
    "X_test, y_test = all_X.iloc[round(len(all_X)*coef):], all_y['Expected'].iloc[round(len(all_X)*coef):]#"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:27:31.851619Z",
     "start_time": "2022-03-09T19:27:30.346369Z"
    }
   },
   "source": [
    "%%timeit\n",
    "# CatBoost\n",
    "\n",
    "from catboost import CatBoostClassifier as cbc\n",
    "\n",
    "est = cbc(iterations=100, depth=5)\n",
    "est.fit(X=X_train.drop('Id', axis=1), y=y_train, silent=True)\n",
    "y_pred = est.predict(X_test)\n",
    "proba = est.predict_proba(X_test)\n",
    "AUC_est = AUC(y_test, proba)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "pr = []\n",
    "for i in range(len(proba)):\n",
    "    d = {0:0, 1:0}\n",
    "    for j in range(len(proba[0])):\n",
    "        d[j] = proba[i,j]\n",
    "    pr += [d]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:27:35.751882Z",
     "start_time": "2022-03-09T19:27:35.597153Z"
    }
   },
   "source": [
    "print(f'AUC: {AUC_est:.3f}')\n",
    "print(f'Accuracy: {acc:.3f}')\n",
    "plot_roc_curve(y_test, pr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:31:46.682716Z",
     "start_time": "2022-03-09T19:31:44.789855Z"
    },
    "scrolled": true
   },
   "source": [
    "%%timeit\n",
    "# Xgboost\n",
    "\n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "est = XGBRFClassifier(n_estimators=100, max_depth=5)\n",
    "est.fit(X_train, y_train)\n",
    "y_pred = est.predict(X_test)\n",
    "proba = est.predict_proba(X_test)\n",
    "AUC_est = AUC(y_test, proba)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "pr = []\n",
    "for i in range(len(proba)):\n",
    "    d = {0:0, 1:0}\n",
    "    for j in range(len(proba[0])):\n",
    "        d[j] = proba[i,j]\n",
    "    pr += [d]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:31:58.439044Z",
     "start_time": "2022-03-09T19:31:58.162489Z"
    }
   },
   "source": [
    "print(f'AUC: {AUC_est:.3f}')\n",
    "print(f'Accuracy: {acc:.3f}')\n",
    "plot_roc_curve(y_test, pr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:41:00.480247Z",
     "start_time": "2022-03-09T19:40:59.045935Z"
    }
   },
   "source": [
    "%%timeit\n",
    "# LightGBM\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "param = {'num_leaves': 31}\n",
    "num_round = 100\n",
    "est = lgb.LGBMClassifier(max_depth=100)\n",
    "est.fit(X_train, y_train)\n",
    "y_pred = est.predict(X_test)\n",
    "proba = est.predict_proba(X_test)\n",
    "AUC_est = AUC(y_test, proba)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "pr = []\n",
    "for i in range(len(proba)):\n",
    "    d = {0:0, 1:0}\n",
    "    for j in range(len(proba[0])):\n",
    "        d[j] = proba[i,j]\n",
    "    pr += [d]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:41:10.667514Z",
     "start_time": "2022-03-09T19:41:10.505833Z"
    }
   },
   "source": [
    "print(f'AUC: {AUC_est:.3f}')\n",
    "print(f'Accuracy: {acc:.3f}')\n",
    "plot_roc_curve(y_test, pr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:50:02.340834Z",
     "start_time": "2022-03-09T19:47:37.324668Z"
    }
   },
   "source": [
    "%%timeit\n",
    "# My forest\n",
    "\n",
    "est = RandomForestClassifier(max_depth=5, n_estimators=100)\n",
    "est.fit(X_train.drop('Id', axis=1), y_train, n_sample=150)\n",
    "y_pred = est.predict(X_test)\n",
    "pr = est.predict_proba(X_test)\n",
    "AUC_est = AUC(y_test, proba)\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T19:44:08.338398Z",
     "start_time": "2022-03-09T19:44:08.221655Z"
    }
   },
   "source": [
    "print(f'AUC: {AUC_est:.3f}')\n",
    "print(f'Accuracy: {acc:.3f}')\n",
    "plot_roc_curve(y_test, pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name         | Time                     | AUC   | Accuracy |\n",
    "|--------------|--------------------------|-------|----------|\n",
    "| CatBoost     | 184 ms ± 7.88 ms         | 0.981 | 0.944    |\n",
    "| Xgboost      | 223 ms ± 81 ms           | 0.960 | 0.912    |\n",
    "| LightGBM     | 165 ms ± 25.1 ms         | 0.979 | 0.944    |\n",
    "| RandomForest | 18.5 s ± 1.21 s per loop | 0.979 | 0.783    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По результатам сравнения, можно сказать, что все готовые решения работают в разы быстрее. \n",
    "Разработанный класс выдает достаточно хорошее по качеству решение, если сравнивать метрику `AUC`. \n",
    "Метрика же `Accuracy` получилась хуже. Из готовых решений лучшим показалось `CatBoost`, в силу хороших\n",
    "метрик и быстрого времени решения задачи. `Xgboost` выдало худшее время (а также предупреждение), что\n",
    "говорит о том, что она меньше всего подходит для решения задачи."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
